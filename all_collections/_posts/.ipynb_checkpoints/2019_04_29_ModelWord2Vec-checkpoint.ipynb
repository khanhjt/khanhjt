{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "qbtHMhlh2yWL"
   },
   "source": [
    "## 1. Giới thiệu Word Representation.\n",
    "Khác với các mô hình xử lý ảnh khi các giá trị đầu vào là cường độ màu sắc đã được mã hoá thành giá trị số trong khoảng [0, 255]. Mô hình xử lý ngôn ngữ tự nhiên có đầu vào chỉ là các chữ cái kết hợp với dấu câu. Làm sao chúng ta có thể lượng hoá được những từ ngữ để làm đầu vào cho mạng nơ ron? Kĩ thuật one-hot véc tơ sẽ được áp dụng để thực hiện điều này. Trước khi đi vào phương pháp biểu diễn, chúng ta cần làm rõ một số khái niệm:\n",
    "\n",
    "* Documents (Văn bản): Là tợp hợp các câu trong cùng một đoạn văn có mối liên hệ với nhau. Văn bản có thể được coi như một bài báo, bài văn,....\n",
    "* Corpus (Bộ văn bản): Là một tợp hợp gồm nhiều văn bản thuộc các đề tài khác nhau, tạo thành một nguồn tài nguyên dạng văn bản. Một văn bản cũng có thể được coi là corpus của các câu trong văn bản. Các bộ văn bảnCác lớn thường có từ vài nghìn đến vài trăm nghìn văn bản trong nó. Một số bộ văn bản trong tiếng việt có thể được download từ nguồn wikipedia, [VNCoreNLP](https://github.com/vncorenlp/VnCoreNLP).\n",
    "* Character (kí tự): Là tợp hợp gồm các chữ cái (nguyên âm và phụ âm) và dấu câu. Mỗi một ngôn ngữ sẽ có một bộ các kí tự khác nhau.\n",
    "* Word (từ vựng): Là các kết hợp của các kí tự tạo thành những từ biểu thị một nội dung, định nghĩa xác định, chẳng hạn `con người` có thể coi là một từ vựng. Từ vựng có thể bao gồm từ đơn có 1 âm tiết và từ ghép nhiều hơn 1 âm tiết. Khác với tiếng anh khi các từ chủ yếu là từ đơn. Tiếng việt có rất nhiều những từ ghép 2, 3 âm tiết. Do đó chúng ta cần phải có từ điển để thực hiện tách từ (tokenize) trong câu. Một số package thông dụng trong Tiếng Việt có sẵn chức năng tách từ được sử dụng phổ biến là [underthesea](https://github.com/undertheseanlp/underthesea ), [pyvi](https://pypi.org/project/pyvi/), [VNCoreNLP](https://github.com/vncorenlp/VnCoreNLP), [RDRsegmenter](https://github.com/datquocnguyen/RDRsegmenter), [coccoc-tokenizer](https://github.com/coccoc/coccoc-tokenizer). Kết quả tokenize có thể khác nhau tuỳ thuộc vào cách định nghĩa từ ghép ở mỗi package. Khi xử lý ngôn ngữ tự nhiên cho một số lĩnh vực đặc biệt cần phải có từ điển chuyên ngành, vì vậy cần phải customize riêng biệt.\n",
    "* Dictionary (từ điển): Là tợp hợp các từ vựng xuất hiện trong văn bản.\n",
    "* Volcabulary (từ vựng): Tợp hợp các từ được trích xuất trong văn bản. Tương tự như từ điển.\n",
    "\n",
    "Trước khi biểu diễn từ chúng ta cần xác định từ điển của corpus. Các từ là hữu hạn và được lặp lại trong quá trình biểu diễn các văn bản trong corpus. Do đó thông qua từ điển gồm tợp hợp tất cả các từ có thể xuất hiện ta sẽ mã hoá được các câu dưới dạng ma trận mà mỗi dòng của nó là một véc tớ one-hot của từ. \n",
    "\n",
    "**Định nghĩa One-hot véc tơ của từ:**\n",
    "Giả sử chúng ta có từ điển là tợp hợp gồm $n$ từ vựng `{anh, em, gia đình, bạn bè,...}`. Khi đó mỗi từ sẽ được đại diện bởi một giá trị chính là index của nó. Từ `anh` có index = 0, `gia đình` có index = 2. One-hot véc tơ của từ vựng thứ $i$, $i \\leq (n-1)$ sẽ là véc tơ $\\mathbf{e}_i = [0, ..., 0, 1, 0, ..., 0] \\in \\mathbb{R}^{n}$ sao cho các phần tử $e_{ij}$ của véc tơ thoả mãn:\n",
    "\n",
    "$$\n",
    "  \\begin{equation}\n",
    "  \\begin{cases}\n",
    "    e_{ij} = 0, & \\text{if}\\space i \\neq j\\\\\n",
    "    e_{ii} = 1\n",
    "  \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "$ \\forall i, j \\in \\mathbb{N}; 0 \\leq i,j  \\leq n-1 $\n",
    "\n",
    "**Hàm biểu diễn One-hot véc tơ:**\n",
    "\n",
    "Trong python chúng ta có thể biến đổi các từ sang dạng one-hot véc tơ thông qua hàm OneHotEncoder của sklearn. Nhưng trước tiên ta sẽ gán index cho các class bằng LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "skk9IcWx2yWN",
    "outputId": "dc259e88-3b00-49ed-a2af-146d400b6a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class of words:  ['anh' 'bạn bè' 'em' 'gia đình']\n",
      "Convert to number:  [0 2 3 1 0 2]\n",
      "Invert into classes:  ['anh' 'em' 'gia đình' 'bạn bè' 'anh' 'em']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "words = ['anh', 'em', 'gia đình', 'bạn bè', 'anh', 'em']\n",
    "le.fit(words)\n",
    "\n",
    "print('Class of words: ', le.classes_)\n",
    "# Biến đổi sang dạng số\n",
    "x = le.transform(words)\n",
    "print('Convert to number: ', x)\n",
    "# Biến đổi lại sang class\n",
    "print('Invert into classes: ', le.inverse_transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "PAYpxNb_2yWY"
   },
   "source": [
    "Thực hiện OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "F7JQzB742yWa",
    "outputId": "e32f79cd-d416-4012-8e54-8076b3620476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes_indices:  [('anh', 0), ('bạn bè', 1), ('em', 2), ('gia đình', 3)]\n",
      "One-hot categories and indices: [array(['anh', 'bạn bè', 'em', 'gia đình'], dtype=object), array([0, 1, 2, 3], dtype=object)]\n",
      "Words and corresponding indices:  [('anh', 0), ('em', 2), ('gia đình', 3), ('bạn bè', 1), ('anh', 0), ('em', 2)]\n",
      "Transform words into one-hot matrices: \n",
      " [[1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0.]]\n",
      "Inverse transform to categories from one-hot matrices: \n",
      " [['anh' 0]\n",
      " ['em' 2]\n",
      " ['gia đình' 3]\n",
      " ['bạn bè' 1]\n",
      " ['anh' 0]\n",
      " ['em' 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "oh = OneHotEncoder()\n",
    "classes_indices = list(zip(le.classes_, np.arange(len(le.classes_))))\n",
    "print('Classes_indices: ', classes_indices)\n",
    "oh.fit(classes_indices)\n",
    "print('One-hot categories and indices:', oh.categories_)\n",
    "# Biến đổi list words sang dạng one-hot\n",
    "words_indices = list(zip(words, x))\n",
    "print('Words and corresponding indices: ', words_indices)\n",
    "one_hot = oh.transform(words_indices).toarray()\n",
    "print('Transform words into one-hot matrices: \\n', one_hot)\n",
    "print('Inverse transform to categories from one-hot matrices: \\n', oh.inverse_transform(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ZcwIvHGe2yWg"
   },
   "source": [
    "## 2. Word Embedding\n",
    "Sau khi biểu diễn từ dưới dạng one-hot véc tơ, mô hình đã có thể học được từ dữ liệu số. Tuy nhiên dữ liệu này chưa đáp ứng được một số tính chất đó là:\n",
    "\n",
    "1. Mối quan hệ tương quan giữa cặp 2 từ khác biệt bất kì luôn là không tương quan (tức bằng 0). Do đó khoảng cách cosine_similarity giữa các từ cùng nhóm và các từ khác là không có sự khác biệt. Trong khi để phân tích được ngữ nghĩa của từ chúng ta cần các véc tơ có khoảng cách của chúng là gần nhau khi từ thuộc cùng 1 nhóm.\n",
    "2. Kích thước của véc tơ sẽ phụ thuộc vào số lượng từ vựng có trong bộ văn bản dẫn đến chi phí tính toán rất lớn khi tập dữ liệu lớn.\n",
    "3. Khi bổ sung thêm các từ vựng mới số chiều của véc tơ có thể thay đổi theo dẫn đến sự không ổn định trong shape.\n",
    "\n",
    "Chính vì thế chúng ta cần phải thực hiện phép nhúng từ bằng các thuật toán nhúng từ (word embedding) sang các véc tơ sao cho:\n",
    "\n",
    "1. Mỗi từ được biểu diễn bởi một véc tơ có số chiều xác định trước.\n",
    "2. Các từ thuộc cùng 1 nhóm thì có khoảng cách gần nhau trong không gian.\n",
    "\n",
    "Xoay quanh các phương pháp nhúng từ chúng ta có rất nhiều cách khác nhau. Nhưng chúng ta có thể có các thuật toán chính sau:\n",
    "\n",
    "* Word2Vec: Về bản chất đây chính là một phép auto encoder nhằm giảm chiều dữ liệu của ma trận đồng xuất hiện của các cặp từ input và output. Trong đó input là từ hiện tại và output là các từ liền kề xung quanh nó. Chẳng hạn chúng ta có 2 câu văn như sau:\n",
    "\n",
    "`Khoa học dữ liệu là một lĩnh vực đòi hỏi kiến thức về toán và lập trình. Tôi rất yêu thích khoa học dữ liệu.`\n",
    "\n",
    "Tập từ điển sẽ bao gồm các từ sau:\n",
    "\n",
    "`[khoa học, dữ liệu, là, một, lĩnh vực, đòi hỏi, kiến thức, về, toán, và, lập trình, tôi, rất, yêu, thích]`\n",
    "\n",
    "Khi đó biểu diễn các từ trong ma trận đồng xuất hiện như bên dưới:\n",
    "\n",
    "<img src = \"https://imgur.com/jRZJH7v.png\" width=\"600px\" height=\"600px\"></img>\n",
    "\n",
    "\n",
    "> **Hình 1:** Ma trận đồng xuất hiện\n",
    "\n",
    "###  2.1. Phương pháp SVD\n",
    "\n",
    "[SVD](https://www.kaggle.com/phamdinhkhanh/singular-value-decomposition) là một phương pháp giảm chiều dữ liệu hiệu quả dựa trên phép phân tích suy biến. Chúng ta cũng có thể tìm ra biểu diễn của mỗi từ trong từ điển bằng một véc tơ các nhân tố ẩn dựa vào việc lựa chọn một số lượng các giá trị đặc trưng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "QW74ROBg2yWi",
    "outputId": "d403e522-60f2-440f-9e42-34d74f5b7fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization of sentences:  ['Khoa học', 'dữ liệu', 'là', 'một', 'lĩnh vực', 'đòi hỏi', 'kiến thức', 'về', 'toán', 'và', 'lập trình', '.', 'Tôi', 'rất', 'yêu thích', 'Khoa học', 'dữ liệu', '.']\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg as ln \n",
    "import numpy as np\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "sentence = 'Khoa học dữ liệu là một lĩnh vực đòi hỏi kiến thức về toán và lập trình. Tôi rất yêu thích Khoa học dữ liệu.'\n",
    "token = word_tokenize(sentence)\n",
    "# Tokenize câu search\n",
    "print('tokenization of sentences: ', token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "zHYE9yw42yWq",
    "outputId": "6c1dc846-9dae-4ba4-80a8-5beb2e754d81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "# Tạo ma trận coherence dưới dạng sparse thông qua khai báo vị trí khác 0 của trục x và y\n",
    "row = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13]\n",
    "col = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14]\n",
    "data =      [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "X = coo_matrix((data, (row, col)), shape=(15, 15)).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "1fFxitL82yWy",
    "outputId": "601ff27d-11df-4bc3-ce38-63ade275de7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U:  (15, 15)\n",
      "Length of diagonal:  15\n",
      "Shape of V:  (15, 15)\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện phân tích suy biến:\n",
    "U, S_diag, V = ln.svd(X)\n",
    "print('Shape of U: ', U.shape)\n",
    "print('Length of diagonal: ', len(S_diag))\n",
    "print('Shape of V: ', V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "F8ENQ1sx2yW5"
   },
   "source": [
    "Các ma trận $\\mathbf{U, V}$ lần lượt là ma trận trực giao suy biến trái và phải. Ma trận $\\mathbf{S}$ là ma trận đường chéo chính. Ta có:\n",
    "$$\\mathbf{U_{15*15}S_{15*15}V_{15*15} = X}$$\n",
    "Đường chéo chính của ma trận $\\mathbf{S_{15*15}}$ được sắp xếp theo thứ tự giảm dần. Cần lựa chọn bao nhiêu chiều dữ liệu để biểu diễn từ sẽ lấy bấy nhiêu dòng của ma trận đường chéo chính. Để véc tơ biểu diễn sát nhất chúng ta nên lấy các dòng tương ứng với các giá trị đặc trưng lớp nhất. Chẳng hạn muốn biểu diễn các từ dưới dạng véc tơ 6 chiều ta lấy tích $\\mathbf{S_{6*15}V_{15*15}} = \\mathbf{X_{6*15}}$. Khi đó các cột của ma trận đầu ra $\\mathbf{X_{6*15}}$ sẽ là một véc tơ nhúng của từ tại vị trí tương ứng trong từ điển."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "tdbtJd1l2yW6",
    "outputId": "e7c544cd-18df-4087-88b9-ac24e475ae76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S truncate: \n",
      " [[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Word Embedding 6 dimensionality: \n",
      " [[0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "S_truncate = np.zeros(shape = (6, 15))\n",
    "np.fill_diagonal(S_truncate, S_diag[:6])\n",
    "print('S truncate: \\n', S_truncate)\n",
    "print('Word Embedding 6 dimensionality: \\n', np.dot(S_truncate, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "NJrLfqFe2yXA"
   },
   "source": [
    "### 2.2. Phương pháp auto encoder\n",
    "\n",
    "Auto encoder được xây dựng trên một mạng nơ ron có 3 layer: input, hidden layer và output. Trong đó số units ở input và output là bằng nhau. Số units ở hidden layer sẽ qui định số chiều của véc tơ biểu diễn từ và thông thường sẽ nhỏ hơn số units ở đầu vào.\n",
    "\n",
    "![Auto Encoder](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522830223/AutoEncoder_kfqad1.png)\n",
    "\n",
    "> **Hình 2:** phương pháp auto encoder với số units ở đầu vào bằng đầu ra.\n",
    "\n",
    "Bên dưới chúng ta sẽ tiến hành nhúng từ thông qua auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "bpX1AvVr2yXC",
    "outputId": "6a80296c-56a1-4a77-a550-f52c740e1295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 96        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 15)                105       \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.5388 - acc: 0.1333\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 585us/step - loss: 2.5290 - acc: 0.0667\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 629us/step - loss: 2.5188 - acc: 0.0667\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 645us/step - loss: 2.5114 - acc: 0.0667\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 719us/step - loss: 2.5023 - acc: 0.0667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff579fdd518>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "def autoencoder(input_unit, hidden_unit):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_unit, input_shape = (15,), activation = 'relu'))\n",
    "    model.add(Dense(hidden_unit, activation = 'relu'))\n",
    "    model.add(Dense(input_unit, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),\n",
    "                 metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model_auto = autoencoder(input_unit = 15, hidden_unit = 6)\n",
    "\n",
    "model_auto.fit(X, X, epochs = 5, batch_size = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "bcyzzcYi2yXJ"
   },
   "source": [
    "Các hệ số kết nối hidden units với một unit ở output sẽ là véc tơ nhúng biểu diễn từ thông qua các nhân tố ẩn. Trích xuất layers cuối cùng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "E14asI3_2yXK",
    "outputId": "33386750-f10e-4916-fa3e-a97d8a3bd750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding_matrix:  (6, 15)\n",
      "Embedding_matrix: \n",
      " [[ 0.38889918  0.5211232  -0.35681784 -0.29142842  0.25496536  0.47015667\n",
      "   0.12295379  0.34093136  0.36910903  0.09683032 -0.41072607 -0.07050186\n",
      "   0.28118226  0.14136976 -0.398313  ]\n",
      " [ 0.18342797 -0.14228119 -0.29116338  0.40031028  0.47284338  0.5166124\n",
      "  -0.47880676  0.49956253  0.36308518  0.07943692  0.46039233 -0.04482159\n",
      "   0.14367305  0.46219113 -0.37292722]\n",
      " [ 0.4906134  -0.00613014 -0.09216617  0.3174584   0.08535323  0.03718374\n",
      "  -0.0576647   0.13673814 -0.0192671   0.16489299 -0.3544627  -0.4466407\n",
      "  -0.46152878  0.35548216  0.19229826]\n",
      " [-0.04221632 -0.2623642  -0.2671243  -0.14902063 -0.08061455  0.08999895\n",
      "   0.22966935 -0.54198337 -0.2509707   0.46091208 -0.06831685 -0.5284586\n",
      "  -0.21089761 -0.13299096  0.36479107]\n",
      " [ 0.09093584  0.38861293  0.24202171  0.20458116 -0.25571942  0.05853903\n",
      "  -0.267772   -0.12935235  0.27599117 -0.25800633  0.2633568  -0.25931272\n",
      "  -0.03536293 -0.29268453 -0.4267695 ]\n",
      " [ 0.26897088  0.24455284 -0.27629155  0.4157534  -0.27802745  0.12034645\n",
      "   0.47979772  0.5275412   0.00355813  0.26329502 -0.18948056  0.00509128\n",
      "   0.4196368   0.4636546   0.08472057]]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = model_auto.layers[2].get_weights()[0]\n",
    "bias = model_auto.layers[2].get_weights()[1]\n",
    "\n",
    "print('Shape of embedding_matrix: ', embedding_matrix.shape)\n",
    "print('Embedding_matrix: \\n', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "WUtzGswT2yXQ",
    "outputId": "f9fc93c6-0c27-45d4-c10b-989f1177af3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5303333"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine(x, y):\n",
    "    cos_sim = np.dot(x, y)/(norm(x)*norm(y))\n",
    "    return cos_sim\n",
    "# Véc tơ biểu diễn từ khoa học\n",
    "e0 = list(embedding_matrix[:, 0])\n",
    "# Véc tơ biểu diễn từ dữ liệu\n",
    "e1 = list(embedding_matrix[:, 1])\n",
    "# Quan hệ tương quan ngữ nghĩa giữa từ khoa học và dữ liệu\n",
    "cosine(e0, e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "q4oHmnIB2yXW"
   },
   "source": [
    "Tìm từ tương quan nhất với một từ thông qua khoảng cách cosine_similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "qkG3N8vJ2yXX",
    "outputId": "be5d4ac7-3a24-4e5d-c289-4e9cae59441e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosines:  [1.0, 0.5303333, -0.59790766, 0.46414658, 0.27999142, 0.6444732, 0.04827654, 0.63190365, 0.52158606, 0.3612144, -0.48850852, -0.4804919, 0.05340819, 0.71187574, -0.27760592]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, 13,  5,  7,  1,  8,  3,  9,  4, 12,  6, 14, 11, 10,  2])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Từ có khoảng cách lớn nhất với từ khoa học theo thứ tự\n",
    "cosines = [cosine(e0, embedding_matrix[:, i]) for i in np.arange(15)]\n",
    "print('cosines: ', cosines)\n",
    "np.argsort([cosine(e0, embedding_matrix[:, i]) for i in np.arange(15)])[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "yEFs46342yXc"
   },
   "source": [
    "như vậy 2 từ ở vị trí thứ 13 và 1 tương ứng với `yêu` và `dữ liệu` là 2 từ có mối liên hệ gần nhất với từ `khoa học`. Xét với bối cảnh của 2 câu văn trên cho thấy khá phù hợp bởi 2 cụm từ: `yêu khoa_học` và `khoa_học dữ_liệu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "VzAgmoEH2yXd"
   },
   "source": [
    "### 2.3. Mô hình word2vec\n",
    "Mô hình word2vec có 2 phương pháp chính là skip-grams và CBOW như sau:\n",
    "\n",
    "**skip-grams**: \n",
    "Giả sử chúng ta có một câu văn như sau: `Tôi muốn một chiếc cốc màu_xanh đựng hoa quả dầm`. Để thu được một phép nhúng từ tốt hơn chúng ta sẽ lựa chọn ra ngẫu nhiên các từ làm bối cảnh (context). Dựa trên từ bối cảnh, các từ mục tiêu (target) sẽ được xác định nằm trong phạm vi xung quanh từ bối cảnh. Chẳng hạn ta  với việc lựa chọn từ `cốc` làm bối cảnh nếu lấy từ tiếp theo, từ liền trước, từ cách đó liền trước 2, 3 từ ta sẽ lần lượt thu được các từ mục tiêu như sau:\n",
    "\n",
    "<table> \n",
    "    <tr> <th>Bối cảnh (context)</th> <th>Mục tiêu (target)</th> </tr> \n",
    "    <tr> <td>cốc</td> <td>màu_xanh</td> </tr> \n",
    "    <tr> <td>cốc</td> <td>chiếc</td> </tr> \n",
    "    <tr> <td>cốc</td> <td>một</td> </tr> \n",
    "    <tr> <td>cốc</td> <td>muốn</td> </tr> \n",
    "</table>\n",
    "\n",
    "\n",
    "Các nghiên cứu cho thấy từ mục tiêu sẽ được giải thích tốt hơn nếu được học theo các từ bối cảnh. Do đó mô hình skip-grams tìm cách xây dựng một thuật toán học có giám sát có đầu vào là các từ bối cảnh --> đầu ra là từ mục tiêu:\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*SR6l59udY05_bUICAjb6-w.png)\n",
    ">**Hình 3**: Kiến trúc mô hình skip-grams. $\\mathbf{w_t}$ là từ bối cảnh, $\\mathbf{w_{t-2}, w_{t-1}, w_{t+1}, w_{t+2}}$ là các từ mục tiêu.\n",
    "\n",
    "* Mục tiêu: $$\\text{Context-c (\"cốc\")} \\rightarrow \\text{Target-t (\"màu_xanh\")}$$\n",
    "Từ từ bối cảnh c ta muốn dự báo từ mục tiêu t\n",
    "\n",
    "* Mô hình:\n",
    "\n",
    "![skip-grams model](https://unixtitan.net/images/network-vector-design-4.png)\n",
    "\n",
    "> **Hình 4**: Kiến trúc mạng nơ ron trong mô hình skip-grams.\n",
    "\n",
    "\n",
    "Cũng giống như các cách tiếp cận thông thường khác, mô hình sẽ biểu diễn một từ bối cảnh dưới dạng one-hot véc tơ $\\mathbf{o_c}$ làm đầu vào cho một mạng nơ ron có tầng ẩn gồm 300 units. Kết quả ở output layer là một hàm softmax tính xác xuất để các từ mục tiêu phân bố vào những từ trong vocabulary (10000 từ). Dựa trên quá trình feed forward và back propagation mô hình sẽ tìm ra tham số tối ưu để kết quả dự báo từ mục tiêu là chuẩn xác nhất. Khi đó quay trở lại tầng hidden layer ta sẽ thu được đầu ra tại tầng này là ma trận nhúng $\\mathbf{E} \\in \\mathbb{R}^{n\\times 300}$. \n",
    "\n",
    "$$\\mathbf{o_c} \\rightarrow \\mathbf{E} \\rightarrow \\mathbf{e_c} \\rightarrow \\text{softmax} \\rightarrow \\mathbf{\\hat{y}}$$\n",
    "$\\mathbf{e_c}$ là véc tơ nhúng trích xuất từ ma trận nhúng $\\mathbf{E}$ tương ứng với từ bối cảnh $\\mathbf{c}$. $\\mathbf{\\hat{y}}$ là xác xuất được dự báo của từ mục tiêu.\n",
    "\n",
    "Khi áp dụng hàm softmax, xác xuất ở đầu ra có dạng:\n",
    "$$\\mathbf{P(t=v_{i}|c)} = \\frac{e^{\\mathbf{\\theta_{i}}^{T}\\mathbf{e_c}}}{\\sum_{j=1}^{10000}e^{\\mathbf{\\theta_{j}}^{T}\\mathbf{e_c}}}$$\n",
    "\n",
    "$\\mathbf{\\theta_{i}} \\in \\mathbb{R}^{300}$ là các véc tơ tham số thể hiện sự liên kết giữa các units ở hidden layer với output layer.\n",
    "\n",
    "Kết quả dự báo mô hình mạng nơ ron càng chuẩn xác thì véc tơ nhúng sẽ càng thể hiện được mối liên hệ trên thực tế giữa từ bối cảnh và mục tiêu chuẩn xác. Do đó nó càng lượng hoá chính xác từ. Kết quả cuối cùng ta quan tâm chính là các dòng của ma trận $\\mathbf{E}$. Chúng là các véc tơ nhúng $\\mathbf{e_c}\\in \\mathbb{R}^{300}$ đại diện cho một từ bối cảnh $\\mathbf{c}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "jnPkyPJV6V9w"
   },
   "source": [
    "**CBOW**: Chúng ta nhận thấy rằng mô hình skip-grams sẽ rất tốn chi phí để tính toán vì mẫu số xác xuất là tổng của toàn bộ số mũ cơ số tự nhiên của vocalbulary. Để hạn chế chi phí tính toán mô hình CBOW (continueos backward model) ra đời chỉ tạo ra một xác xuất duy nhất thay vì 10000 xác xuất ở đầu ra. Xuất phát từ ý tưởng đó, mô hình sẽ xây dựng kiến trúc dự báo chỉ gồm 1 đầu ra duy nhất là từ ở vị trí trung tâm được dự báo từ đầu vào là các từ bối cảnh.\n",
    "\n",
    "\n",
    "![CBOW](https://cdn-images-1.medium.com/max/800/1*UVe8b6CWYykcxbBOR6uCfg.png)\n",
    "> **Hình 4**: Kiến trúc CBOW \n",
    "\n",
    "Bên dưới chúng ta cùng sử dụng mô hình word2vec theo phương pháp CBOW để nhúng các từ bối cảnh thành những véc tơ có 300 chiều bằng `keras`. Dữ liệu input là các câu trong kinh thánh được lấy từ [bible-kjv.txt](http://www.gutenberg.org/ebooks/10). Để xây dựng mô hình sẽ đi qua các bước sau đây:\n",
    "\n",
    "1. Tạo bộ từ điển cho toàn bộ các câu trong kinh thánh sao cho mỗi từ được gán giá trị bởi 1 số index.\n",
    "2. Mã hoá toàn bộ các câu văn bằng index. \n",
    "3. Xác định các cặp `Context --> Target` tương ứng với input và output của mô hình. Trong đó từ `Target` là từ hiện tại ở vị trí `index`, các từ `Context` nằm ở khoảng `[index - window_size, index + window_size]`. Padding giá trị 0 tại những context không đủ độ dài là `2*window_size`.\n",
    "4. Xây dựng mạng nơ ron.\n",
    "5. Huấn luyện mô hình.\n",
    "6. Trích xuất ma trận nhúng tại đầu ra của hidden layer.\n",
    "\n",
    "Bước 1: Tạo từ điển"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "8RrgzmAC2yXe",
    "outputId": "f1921ea1-d8b5-42c2-b4e6-874ba0e3ab90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Vocabulary Size: 12746\n",
      "Vocabulary Sample: [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('that', 5), ('in', 6), ('he', 7), ('shall', 8), ('unto', 9), ('for', 10)]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "norm_bible = gutenberg.sents('bible-kjv.txt') \n",
    "norm_bible = [' '.join(doc) for doc in norm_bible]\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(norm_bible)\n",
    "word2id = tokenizer.word_index\n",
    "\n",
    "# build vocabulary of unique words\n",
    "word2id['PAD'] = 0\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "FAnB_BcN2yXk"
   },
   "source": [
    "Bước 2: Mã hoá toàn bộ các câu văn bằng index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "LmyYn1An2yXk",
    "outputId": "b34f6bae-6b86-49b5-d881-ff6ed8995c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding sentence by index:  [[1, 53, 1342, 6058], [1, 280, 2678, 3, 1, 53, 1342, 6058], [1, 254, 448, 3, 162, 194, 8769], [43, 43, 6, 1, 734, 27, 1368, 1, 205, 2, 1, 139], [43, 48, 2, 1, 139, 26, 258, 2085, 2, 2086, 2, 551, 26, 46, 1, 266, 3, 1, 1030]]\n"
     ]
    }
   ],
   "source": [
    "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_bible]\n",
    "print('Embedding sentence by index: ', wids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "vPqq7dAM2yXp"
   },
   "source": [
    "Bước 3: Xác định `Context --> Target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "bFp8m2g82yXq",
    "outputId": "175ea207-9484-4468-898f-af7cd1891ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context (X): ['the', 'old', 'of', 'the'] -> Target (Y): testament\n",
      "Context (X): ['old', 'testament', 'the', 'king'] -> Target (Y): of\n",
      "Context (X): ['testament', 'of', 'king', 'james'] -> Target (Y): the\n",
      "Context (X): ['of', 'the', 'james', 'bible'] -> Target (Y): king\n",
      "Context (X): ['the', 'first', 'of', 'moses'] -> Target (Y): book\n",
      "Context (X): ['first', 'book', 'moses', 'called'] -> Target (Y): of\n",
      "Context (X): ['book', 'of', 'called', 'genesis'] -> Target (Y): moses\n",
      "Context (X): ['1', '1', 'the', 'beginning'] -> Target (Y): in\n",
      "Context (X): ['1', 'in', 'beginning', 'god'] -> Target (Y): the\n",
      "Context (X): ['in', 'the', 'god', 'created'] -> Target (Y): beginning\n",
      "Context (X): ['the', 'beginning', 'created', 'the'] -> Target (Y): god\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
    "    context_length = window_size*2\n",
    "    for words in corpus:\n",
    "        sentence_length = len(words)\n",
    "        # print('words: ', words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words = []\n",
    "            label_word   = [] \n",
    "            # Start index of context\n",
    "            start = index - window_size\n",
    "            # End index of context\n",
    "            end = index + window_size + 1\n",
    "            # List of context_words\n",
    "            context_words.append([words[i] for i in range(start, end) if 0 <= i < sentence_length and i != index])\n",
    "            # List of label_word (also is target word).\n",
    "            # print('context words {}: {}'.format(context_words, index))\n",
    "            label_word.append(word)\n",
    "            # Padding the input 0 in the left in case it does not satisfy number of context_words = 2*window_size.\n",
    "            x = sequence.pad_sequences(context_words, maxlen=context_length)\n",
    "            # print('context words padded: ', x)\n",
    "            # Convert label_word into one-hot vector corresponding with its index\n",
    "            y = np_utils.to_categorical(label_word, vocab_size)\n",
    "            yield (x, y)\n",
    "            \n",
    "            \n",
    "# Test this out for some samples\n",
    "i = 0\n",
    "window_size = 2 # context window size\n",
    "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "    if 0 not in x[0]:\n",
    "        print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
    "    \n",
    "        if i == 10:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "d0vdTJ-82yXu"
   },
   "source": [
    "Bước 4: Xây dựng mạng nơ ron gồm 3 layers chính: \n",
    "1. Embedding layer: dùng để mã hoá đầu vào thành các one-hot véc tơ. Số lượng từ ở đầu vào chính là `2*window_size`. Sau khi mã hoá, qua quá trình training mỗi một từ vựng sẽ được biểu diễn bởi một véc tơ nhúng 100 chiều tương ứng với `embed_size`.\n",
    "2. Mean layer: Tính véc tơ trung bình của các véc tơ đầu ra ở Embedding layer. Số lượng véc tơ là `2*window_size`.\n",
    "3. Dense layer: Tính phân phối xác xuất của từ `Target` dựa vào hàm softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "MRxXeHlh2yXv",
    "outputId": "dd5ffa6f-26ec-4551-8158-e060b2f06c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 100)            1274600   \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12746)             1287346   \n",
      "=================================================================\n",
      "Total params: 2,561,946\n",
      "Trainable params: 2,561,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "embed_size = 100\n",
    "\n",
    "# build CBOW architecture\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
    "cbow.add(Dense(vocab_size, activation='softmax'))\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# view model summary\n",
    "print(cbow.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "qnAWAmAcEo9T",
    "outputId": "59abb80c-7c81-4836-83ed-2c6d250cb76c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of window:  30103\n"
     ]
    }
   ],
   "source": [
    "print('number of window: ', len(wids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "yE0FAOjkRjX8"
   },
   "source": [
    "Bước 5: Huấn luyện mô hình. \n",
    "Chúng ta sẽ huấn luyện mô hình dựa trên 100 câu văn đầu tiên và trải qua 5 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "iJLWM9Bj2yXy",
    "outputId": "00e80ae0-38a8-4783-cad7-173f78898b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 (context, word) pairs\n",
      "Processed 1000 (context, word) pairs\n",
      "Processed 1500 (context, word) pairs\n",
      "Processed 2000 (context, word) pairs\n",
      "Processed 2500 (context, word) pairs\n",
      "Epoch: 1 \tLoss: 16144.638676483184\n",
      "Processed 500 (context, word) pairs\n",
      "Processed 1000 (context, word) pairs\n",
      "Processed 1500 (context, word) pairs\n",
      "Processed 2000 (context, word) pairs\n",
      "Processed 2500 (context, word) pairs\n",
      "Epoch: 2 \tLoss: 15855.159716077149\n",
      "Processed 500 (context, word) pairs\n",
      "Processed 1000 (context, word) pairs\n",
      "Processed 1500 (context, word) pairs\n",
      "Processed 2000 (context, word) pairs\n",
      "Processed 2500 (context, word) pairs\n",
      "Epoch: 3 \tLoss: 16312.521473242901\n",
      "Processed 500 (context, word) pairs\n",
      "Processed 1000 (context, word) pairs\n",
      "Processed 1500 (context, word) pairs\n",
      "Processed 2000 (context, word) pairs\n",
      "Processed 2500 (context, word) pairs\n",
      "Epoch: 4 \tLoss: 16708.009846252855\n",
      "Processed 500 (context, word) pairs\n",
      "Processed 1000 (context, word) pairs\n",
      "Processed 1500 (context, word) pairs\n",
      "Processed 2000 (context, word) pairs\n",
      "Processed 2500 (context, word) pairs\n",
      "Epoch: 5 \tLoss: 16937.563758765813\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0.\n",
    "    i = 0\n",
    "    for x, y in generate_context_word_pairs(corpus=wids[:100], window_size=window_size, vocab_size=vocab_size):\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "        if i % 500 == 0:\n",
    "            print('Processed {} (context, word) pairs'.format(i))\n",
    "\n",
    "    print('Epoch:', epoch, '\\tLoss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "gwKEFeFMLfkd"
   },
   "source": [
    "Bước 6: Trích xuất ma trận nhúng của các từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "LBBihl4tLdIE",
    "outputId": "a6677194-49e5-4123-9d51-4417643ad3f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12745, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.566605</td>\n",
       "      <td>0.193528</td>\n",
       "      <td>0.580568</td>\n",
       "      <td>0.399872</td>\n",
       "      <td>-0.477950</td>\n",
       "      <td>0.058564</td>\n",
       "      <td>0.136201</td>\n",
       "      <td>-0.180622</td>\n",
       "      <td>0.332103</td>\n",
       "      <td>-0.126461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066192</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.221867</td>\n",
       "      <td>0.187878</td>\n",
       "      <td>-0.256676</td>\n",
       "      <td>-0.240416</td>\n",
       "      <td>-0.254147</td>\n",
       "      <td>0.254194</td>\n",
       "      <td>0.051008</td>\n",
       "      <td>-0.229002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.006290</td>\n",
       "      <td>1.063426</td>\n",
       "      <td>-0.064591</td>\n",
       "      <td>0.273369</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.099132</td>\n",
       "      <td>0.092056</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>-0.223147</td>\n",
       "      <td>-0.510919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263550</td>\n",
       "      <td>0.419170</td>\n",
       "      <td>0.212709</td>\n",
       "      <td>0.760192</td>\n",
       "      <td>-0.473723</td>\n",
       "      <td>-0.481127</td>\n",
       "      <td>-0.586069</td>\n",
       "      <td>0.514270</td>\n",
       "      <td>-0.046415</td>\n",
       "      <td>-0.021855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.212710</td>\n",
       "      <td>1.351286</td>\n",
       "      <td>0.431805</td>\n",
       "      <td>0.586412</td>\n",
       "      <td>-0.079169</td>\n",
       "      <td>-0.097280</td>\n",
       "      <td>-0.117581</td>\n",
       "      <td>0.064991</td>\n",
       "      <td>0.095262</td>\n",
       "      <td>-0.399057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>-0.047217</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>-0.407661</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>-0.167975</td>\n",
       "      <td>-0.119068</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>-0.339243</td>\n",
       "      <td>-0.166616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.584896</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>0.090305</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>-0.115047</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>0.204439</td>\n",
       "      <td>-0.182319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117154</td>\n",
       "      <td>0.324759</td>\n",
       "      <td>0.126172</td>\n",
       "      <td>-0.197954</td>\n",
       "      <td>-0.247685</td>\n",
       "      <td>-0.221629</td>\n",
       "      <td>-0.193981</td>\n",
       "      <td>0.213249</td>\n",
       "      <td>-0.370214</td>\n",
       "      <td>0.263854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.167913</td>\n",
       "      <td>0.545757</td>\n",
       "      <td>-0.136884</td>\n",
       "      <td>0.033220</td>\n",
       "      <td>-0.025752</td>\n",
       "      <td>0.112379</td>\n",
       "      <td>-0.253199</td>\n",
       "      <td>0.116862</td>\n",
       "      <td>0.254202</td>\n",
       "      <td>0.242693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087999</td>\n",
       "      <td>-0.037836</td>\n",
       "      <td>0.077510</td>\n",
       "      <td>-0.073683</td>\n",
       "      <td>-0.367073</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>-0.177120</td>\n",
       "      <td>-0.188733</td>\n",
       "      <td>-0.347490</td>\n",
       "      <td>0.165443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "and   0.566605  0.193528  0.580568  0.399872 -0.477950  0.058564  0.136201   \n",
       "of   -0.006290  1.063426 -0.064591  0.273369  0.005391 -0.099132  0.092056   \n",
       "to    0.212710  1.351286  0.431805  0.586412 -0.079169 -0.097280 -0.117581   \n",
       "that  0.105932  0.584896  0.032046  0.090305  0.009700  0.017799 -0.115047   \n",
       "in    0.167913  0.545757 -0.136884  0.033220 -0.025752  0.112379 -0.253199   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "and  -0.180622  0.332103 -0.126461  ... -0.066192  0.102113  0.221867   \n",
       "of    0.334700 -0.223147 -0.510919  ... -0.263550  0.419170  0.212709   \n",
       "to    0.064991  0.095262 -0.399057  ...  0.089253 -0.047217  0.033623   \n",
       "that -0.002097  0.204439 -0.182319  ... -0.117154  0.324759  0.126172   \n",
       "in    0.116862  0.254202  0.242693  ... -0.087999 -0.037836  0.077510   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "and   0.187878 -0.256676 -0.240416 -0.254147  0.254194  0.051008 -0.229002  \n",
       "of    0.760192 -0.473723 -0.481127 -0.586069  0.514270 -0.046415 -0.021855  \n",
       "to   -0.407661  0.051037 -0.167975 -0.119068  0.153845 -0.339243 -0.166616  \n",
       "that -0.197954 -0.247685 -0.221629 -0.193981  0.213249 -0.370214  0.263854  \n",
       "in   -0.073683 -0.367073 -0.033356 -0.177120 -0.188733 -0.347490  0.165443  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weights = cbow.get_weights()[0]\n",
    "weights = weights[1:]\n",
    "print(weights.shape)\n",
    "\n",
    "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "Y1TXG4Up2yX1",
    "outputId": "afd373eb-ee4f-4978-baf7-4d5d198479bd"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"294pt\" viewBox=\"0.00 0.00 252.00 294.00\" width=\"252pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 290)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-290 248,-290 248,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140692379161208 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140692379161208</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 244,-212.5 244,-166.5 0,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-185.8\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"84,-166.5 84,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"84,-189.5 142,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"142,-166.5 142,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-197.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"142,-189.5 244,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-174.3\">(None, 4, 100)</text>\n",
       "</g>\n",
       "<!-- 140692379161432 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140692379161432</title>\n",
       "<polygon fill=\"none\" points=\"10,-83.5 10,-129.5 234,-129.5 234,-83.5 10,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-102.8\">Lambda</text>\n",
       "<polyline fill=\"none\" points=\"74,-83.5 74,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"74,-106.5 132,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"132,-83.5 132,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-114.3\">(None, 4, 100)</text>\n",
       "<polyline fill=\"none\" points=\"132,-106.5 234,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140692379161208&#45;&gt;140692379161432 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140692379161208-&gt;140692379161432</title>\n",
       "<path d=\"M122,-166.3799C122,-158.1745 122,-148.7679 122,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"125.5001,-139.784 122,-129.784 118.5001,-139.784 125.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140692996455280 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140692996455280</title>\n",
       "<polygon fill=\"none\" points=\"16,-.5 16,-46.5 228,-46.5 228,-.5 16,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-19.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"68,-.5 68,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"68,-23.5 126,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126,-.5 126,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-31.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"126,-23.5 228,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-8.3\">(None, 12746)</text>\n",
       "</g>\n",
       "<!-- 140692379161432&#45;&gt;140692996455280 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140692379161432-&gt;140692996455280</title>\n",
       "<path d=\"M122,-83.3799C122,-75.1745 122,-65.7679 122,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"125.5001,-56.784 122,-46.784 118.5001,-56.784 125.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140692379162048 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140692379162048</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-249.5 57.5,-285.5 186.5,-285.5 186.5,-249.5 57.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122\" y=\"-263.8\">140692379162048</text>\n",
       "</g>\n",
       "<!-- 140692379162048&#45;&gt;140692379161208 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140692379162048-&gt;140692379161208</title>\n",
       "<path d=\"M122,-249.4092C122,-241.4308 122,-231.795 122,-222.606\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"125.5001,-222.5333 122,-212.5333 118.5001,-222.5334 125.5001,-222.5333\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "TLJJC_d32yX3"
   },
   "source": [
    "Hoàn toàn tương tự như kiến trúc của **CBOW**, ta  xây dựng model **skip-grams** như sau:\n",
    "\n",
    "Bước 1: Chuẩn bị dữ liệu là các cặp [context, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "YJBAEk9C2yX4",
    "outputId": "a2957558-951a-4760-d2e6-44833fac6203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(the (1), harmless (6878)) -> 0\n",
      "(king (53), ramoth (4038)) -> 0\n",
      "(james (1342), bible (6058)) -> 1\n",
      "(king (53), bible (6058)) -> 1\n",
      "(james (1342), moist (9056)) -> 0\n",
      "(james (1342), coffer (6377)) -> 0\n",
      "(bible (6058), james (1342)) -> 1\n",
      "(james (1342), lintels (11682)) -> 0\n",
      "(king (53), give (155)) -> 0\n",
      "(the (1), james (1342)) -> 1\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "# generate skip-grams\n",
    "skip_grams = [skipgrams(wid, vocabulary_size=vocab_size, window_size=window_size) for wid in wids[:100]]\n",
    "\n",
    "# view sample skip-grams\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(10):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          id2word[pairs[i][0]], pairs[i][0], \n",
    "          id2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "b4PGLh9Kawfe"
   },
   "source": [
    "Bước 2: Xây dựng mạng nơ ron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1035
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "gwXXsqCY2yX6",
    "outputId": "0f4d6cde-1b37-496f-82ce-2579d11b8d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "word_embedding (Embedding)   (None, 1, 100)            1274600   \n",
      "_________________________________________________________________\n",
      "reshape_21 (Reshape)         (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 1,274,600\n",
      "Trainable params: 1,274,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "word_model: \n",
      " None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "context_embedding (Embedding (None, 1, 100)            1274600   \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 1,274,600\n",
      "Trainable params: 1,274,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "context_model: \n",
      " None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_embedding (Embedding)      (None, 1, 100)       1274600     input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding (Embedding)   (None, 1, 100)       1274600     input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 100)          0           word_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 100)          0           context_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 1)            0           reshape_21[0][0]                 \n",
      "                                                                 reshape_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            2           dot_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,549,202\n",
      "Trainable params: 2,549,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "model merge word and context: \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dot, dot, concatenate\n",
    "# from keras.engine.input_layer import Input\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Model, Input\n",
    "\n",
    "# build skip-gram architecture\n",
    "word_input = Input(shape = (1,))\n",
    "word_embed = Embedding(vocab_size, embed_size,\n",
    "                         embeddings_initializer=\"glorot_uniform\",\n",
    "                         input_length=1, name = 'word_embedding')(word_input)\n",
    "word_output = Reshape((embed_size, ))(word_embed)\n",
    "word_model = Model(word_input, word_output)\n",
    "\n",
    "print('word_model: \\n', word_model.summary())\n",
    "context_input = Input(shape = (1,))\n",
    "context_embed = Embedding(vocab_size, embed_size,\n",
    "                  embeddings_initializer=\"glorot_uniform\",\n",
    "                  input_length=1, name = 'context_embedding')(context_input)\n",
    "context_output = Reshape((embed_size,))(context_embed)\n",
    "context_model = Model(context_input, context_output)\n",
    "print('context_model: \\n', context_model.summary())\n",
    "\n",
    "concate = dot([word_output, context_output], axes = -1)\n",
    "dense = Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\")(concate)\n",
    "model = Model(inputs = [word_input, context_input], outputs = dense)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "\n",
    "# view model summary\n",
    "print('model merge word and context: \\n', model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "emQNu4uk9wF4",
    "outputId": "b3c41017-fda0-4008-d251-cc95bf6bcb4d"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 514.00 387.00\" width=\"514pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 510,-383 510,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140602678555648 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140602678555648</title>\n",
       "<polygon fill=\"none\" points=\"17,-332.5 17,-378.5 227,-378.5 227,-332.5 17,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"57\" y=\"-351.8\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"97,-332.5 97,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"97,-355.5 155,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"155,-332.5 155,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"155,-355.5 227,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140602678555704 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140602678555704</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 244,-295.5 244,-249.5 0,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-268.8\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"84,-249.5 84,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"84,-272.5 142,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"142,-249.5 142,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"142,-272.5 244,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-257.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 140602678555648&#45;&gt;140602678555704 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140602678555648-&gt;140602678555704</title>\n",
       "<path d=\"M122,-332.3799C122,-324.1745 122,-314.7679 122,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"125.5001,-305.784 122,-295.784 118.5001,-305.784 125.5001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140602678557720 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140602678557720</title>\n",
       "<polygon fill=\"none\" points=\"279,-332.5 279,-378.5 489,-378.5 489,-332.5 279,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-351.8\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"359,-332.5 359,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"359,-355.5 417,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"417,-332.5 417,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"417,-355.5 489,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140602678556264 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140602678556264</title>\n",
       "<polygon fill=\"none\" points=\"262,-249.5 262,-295.5 506,-295.5 506,-249.5 262,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-268.8\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"346,-249.5 346,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"346,-272.5 404,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"404,-249.5 404,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"455\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"404,-272.5 506,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"455\" y=\"-257.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 140602678557720&#45;&gt;140602678556264 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140602678557720-&gt;140602678556264</title>\n",
       "<path d=\"M384,-332.3799C384,-324.1745 384,-314.7679 384,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"387.5001,-305.784 384,-295.784 380.5001,-305.784 387.5001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140602660736192 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140602660736192</title>\n",
       "<polygon fill=\"none\" points=\"18.5,-166.5 18.5,-212.5 243.5,-212.5 243.5,-166.5 18.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"51\" y=\"-185.8\">Reshape</text>\n",
       "<polyline fill=\"none\" points=\"83.5,-166.5 83.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"112.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"83.5,-189.5 141.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"112.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"141.5,-166.5 141.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-197.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"141.5,-189.5 243.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-174.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140602678555704&#45;&gt;140602660736192 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140602678555704-&gt;140602660736192</title>\n",
       "<path d=\"M124.507,-249.3799C125.3967,-241.1745 126.4167,-231.7679 127.3806,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"130.8767,-223.1031 128.4752,-212.784 123.9175,-222.3484 130.8767,-223.1031\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140602678556488 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140602678556488</title>\n",
       "<polygon fill=\"none\" points=\"266.5,-166.5 266.5,-212.5 491.5,-212.5 491.5,-166.5 266.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-185.8\">Reshape</text>\n",
       "<polyline fill=\"none\" points=\"331.5,-166.5 331.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"331.5,-189.5 389.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"389.5,-166.5 389.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"440.5\" y=\"-197.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"389.5,-189.5 491.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"440.5\" y=\"-174.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140602678556264&#45;&gt;140602678556488 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140602678556264-&gt;140602678556488</title>\n",
       "<path d=\"M382.6072,-249.3799C382.1129,-241.1745 381.5463,-231.7679 381.0108,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"384.4977,-222.5554 380.4027,-212.784 377.5104,-222.9764 384.4977,-222.5554\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140602658332176 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140602658332176</title>\n",
       "<polygon fill=\"none\" points=\"117,-83.5 117,-129.5 387,-129.5 387,-83.5 117,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"136\" y=\"-102.8\">Dot</text>\n",
       "<polyline fill=\"none\" points=\"155,-83.5 155,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"155,-106.5 213,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"213,-83.5 213,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-114.3\">[(None, 100), (None, 100)]</text>\n",
       "<polyline fill=\"none\" points=\"213,-106.5 387,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-91.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140602660736192&#45;&gt;140602658332176 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140602660736192-&gt;140602658332176</title>\n",
       "<path d=\"M164.7052,-166.3799C178.6176,-156.8367 194.8988,-145.6686 209.6073,-135.5793\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"211.7893,-138.3269 218.0558,-129.784 207.8296,-132.5544 211.7893,-138.3269\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140602678556488&#45;&gt;140602658332176 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140602678556488-&gt;140602658332176</title>\n",
       "<path d=\"M343.6234,-166.3799C328.8848,-156.7475 311.613,-145.4597 296.0625,-135.2967\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"297.913,-132.325 287.6273,-129.784 294.0834,-138.1846 297.913,-132.325\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140602658331784 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140602658331784</title>\n",
       "<polygon fill=\"none\" points=\"161,-.5 161,-46.5 343,-46.5 343,-.5 161,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-19.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"213,-.5 213,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"213,-23.5 271,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"271,-.5 271,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-31.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"271,-23.5 343,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140602658332176&#45;&gt;140602658331784 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140602658332176-&gt;140602658331784</title>\n",
       "<path d=\"M252,-83.3799C252,-75.1745 252,-65.7679 252,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"255.5001,-56.784 252,-46.784 248.5001,-56.784 255.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "pxrHkGCdBx2c"
   },
   "source": [
    "Bước 3: Huấn luyện mô hình.\n",
    "\n",
    "Để cho nhanh thì mình sẽ training trên 100 skip_grams đầu tiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "kWvcOkykavFu",
    "outputId": "98e2ff9d-f1c5-462a-ff43-b98342f02f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 1 Loss: 24.676736623048782\n",
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 2 Loss: 22.21561288833618\n",
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 3 Loss: 18.663180768489838\n",
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 4 Loss: 15.21924028545618\n",
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 5 Loss: 12.227664299309254\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for i, elem in enumerate(skip_grams[:100]):\n",
    "        pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "        pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "        labels = np.array(elem[1], dtype='int32')\n",
    "        X = [pair_first_elem, pair_second_elem]\n",
    "        Y = labels\n",
    "        if i % 500 == 0:\n",
    "            print('Processed {} (skip_first, skip_second, relevance) pairs'.format(i))\n",
    "        loss += model.train_on_batch(X,Y)  \n",
    "\n",
    "    print('Epoch:', epoch, 'Loss:', loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "xAMywislBt31"
   },
   "source": [
    "Bước 4: Trích xuất ra véc tơ nhúng ở layer đầu tiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "31X3pOfP-ub1",
    "outputId": "fabe435d-6574-47aa-c6ad-c777557fd02a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12746, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.017877</td>\n",
       "      <td>-0.006345</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.013126</td>\n",
       "      <td>-0.012344</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>-0.021061</td>\n",
       "      <td>-0.018586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020651</td>\n",
       "      <td>0.013076</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>0.013153</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>-0.013620</td>\n",
       "      <td>-0.003691</td>\n",
       "      <td>-0.012306</td>\n",
       "      <td>0.013466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.382729</td>\n",
       "      <td>0.396258</td>\n",
       "      <td>-0.364188</td>\n",
       "      <td>0.380298</td>\n",
       "      <td>-0.391238</td>\n",
       "      <td>0.368729</td>\n",
       "      <td>0.358361</td>\n",
       "      <td>0.386061</td>\n",
       "      <td>0.325783</td>\n",
       "      <td>0.334060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363881</td>\n",
       "      <td>0.367605</td>\n",
       "      <td>-0.358629</td>\n",
       "      <td>-0.358335</td>\n",
       "      <td>-0.375458</td>\n",
       "      <td>0.355854</td>\n",
       "      <td>-0.301842</td>\n",
       "      <td>0.399266</td>\n",
       "      <td>-0.362073</td>\n",
       "      <td>-0.392506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.349388</td>\n",
       "      <td>0.410817</td>\n",
       "      <td>-0.408293</td>\n",
       "      <td>0.396892</td>\n",
       "      <td>-0.386039</td>\n",
       "      <td>0.360959</td>\n",
       "      <td>0.393057</td>\n",
       "      <td>0.292898</td>\n",
       "      <td>0.354751</td>\n",
       "      <td>-0.366920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378525</td>\n",
       "      <td>0.407809</td>\n",
       "      <td>-0.411903</td>\n",
       "      <td>0.257437</td>\n",
       "      <td>-0.376674</td>\n",
       "      <td>0.404098</td>\n",
       "      <td>0.172114</td>\n",
       "      <td>0.395809</td>\n",
       "      <td>-0.394699</td>\n",
       "      <td>-0.373308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.272330</td>\n",
       "      <td>0.324286</td>\n",
       "      <td>-0.283027</td>\n",
       "      <td>0.296941</td>\n",
       "      <td>-0.275317</td>\n",
       "      <td>0.268769</td>\n",
       "      <td>0.288633</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>-0.203013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265409</td>\n",
       "      <td>0.290523</td>\n",
       "      <td>-0.281284</td>\n",
       "      <td>-0.086492</td>\n",
       "      <td>-0.265537</td>\n",
       "      <td>0.257802</td>\n",
       "      <td>0.156399</td>\n",
       "      <td>0.288598</td>\n",
       "      <td>-0.255115</td>\n",
       "      <td>-0.291732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.198596</td>\n",
       "      <td>0.185280</td>\n",
       "      <td>-0.195971</td>\n",
       "      <td>0.194342</td>\n",
       "      <td>-0.172201</td>\n",
       "      <td>0.198094</td>\n",
       "      <td>0.193203</td>\n",
       "      <td>0.124202</td>\n",
       "      <td>0.142453</td>\n",
       "      <td>-0.162316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.151464</td>\n",
       "      <td>-0.189423</td>\n",
       "      <td>-0.135934</td>\n",
       "      <td>-0.167137</td>\n",
       "      <td>0.178498</td>\n",
       "      <td>-0.119129</td>\n",
       "      <td>0.177591</td>\n",
       "      <td>-0.180071</td>\n",
       "      <td>-0.166930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "the   0.017877 -0.006345  0.010881  0.013126 -0.012344  0.001429  0.013889   \n",
       "and   0.382729  0.396258 -0.364188  0.380298 -0.391238  0.368729  0.358361   \n",
       "of    0.349388  0.410817 -0.408293  0.396892 -0.386039  0.360959  0.393057   \n",
       "to    0.272330  0.324286 -0.283027  0.296941 -0.275317  0.268769  0.288633   \n",
       "that  0.198596  0.185280 -0.195971  0.194342 -0.172201  0.198094  0.193203   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "the   0.003133 -0.021061 -0.018586  ... -0.020651  0.013076 -0.021328   \n",
       "and   0.386061  0.325783  0.334060  ...  0.363881  0.367605 -0.358629   \n",
       "of    0.292898  0.354751 -0.366920  ...  0.378525  0.407809 -0.411903   \n",
       "to    0.217401  0.276515 -0.203013  ...  0.265409  0.290523 -0.281284   \n",
       "that  0.124202  0.142453 -0.162316  ...  0.179012  0.151464 -0.189423   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "the   0.013153  0.007915  0.001992 -0.013620 -0.003691 -0.012306  0.013466  \n",
       "and  -0.358335 -0.375458  0.355854 -0.301842  0.399266 -0.362073 -0.392506  \n",
       "of    0.257437 -0.376674  0.404098  0.172114  0.395809 -0.394699 -0.373308  \n",
       "to   -0.086492 -0.265537  0.257802  0.156399  0.288598 -0.255115 -0.291732  \n",
       "that -0.135934 -0.167137  0.178498 -0.119129  0.177591 -0.180071 -0.166930  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "word_embedding_layer = model.get_layer('word_embedding')\n",
    "weights = word_embedding_layer.get_weights()[0]\n",
    "\n",
    "print(weights.shape)\n",
    "pd.DataFrame(weights, index=id2word.values()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "7ejeyfySFF7_"
   },
   "source": [
    "Tìm các từ gần nghĩa nhất với 2 từ `['egypt', 'king']` dựa trên khoảng cách euclidean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "PcNM1IIZCKgC",
    "outputId": "98928d41-3cee-4a08-a44c-a66d9e87eee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12746, 12746)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'egypt': ['ethiopia', 'earth', 'dwell', 'go', 'from'],\n",
       " 'king': ['out', 'these', 'by', 'lord', 'son']}"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "distance_matrix = euclidean_distances(weights)\n",
    "print(distance_matrix.shape)\n",
    "\n",
    "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:6]+1] \n",
    "                   for search_term in ['egypt', 'king']}\n",
    "\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "SkuHd3RsFiox"
   },
   "source": [
    "Biểu diễn các từ trong không gian nén 100 chiều về 2 chiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "6ur0CqafF0-n",
    "outputId": "10fb4e5b-7765-4f52-f290-9b4733550fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 12 \tWord Embedding shapes: (12, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAHVCAYAAAA3lfClAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAeIUQBAAAAMArhCAAAAAAXvn/MmB3KDTTopcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = sum([[k] + v for k, v in similar_words.items()], [])\n",
    "words_ids = [word2id[w] for w in words]\n",
    "word_vectors = np.array([weights[idx] for idx in words_ids])\n",
    "print('Total words:', len(words), '\\tWord Embedding shapes:', word_vectors.shape)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0, n_iter=10000, perplexity=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(word_vectors)\n",
    "labels = words\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='steelblue', edgecolors='k')\n",
    "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "0e67Iz-JGKmK"
   },
   "source": [
    "Để tiết kiệm thời gian, tôi chỉ training với 100 skip-grams đầu tiên nên mô hình chưa phản ánh được chuẩn xác mối quan hệ của từ. Bạn đọc có thể tăng số lượng skip-grams để các từ có mối liên hệ gần sẽ được nhóm vào 1 nhóm trên biểu đồ TSNE.\n",
    "\n",
    "## 1.3. Sử dụng gensim cho mô hình word2vec\n",
    "\n",
    "Cách training trên chỉ sử dụng để chúng ta hiểu rõ cơ chế hoạt động của 2 phương pháp **skip-grams** và **CBOW** trong mô hình word2vec. Trên thực tế mô hình có thể được training trên gensim với chỉ 1 vài dòng rất đơn giản như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "KHMWcik0HDgg",
    "outputId": "c309e54d-6b2f-4402-cc9c-b7bdb1009c69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210070, 336740)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# Training model với 1000 câu đầu tiên trong kinh thánh\n",
    "sentences = [[item.lower() for item in doc.split()] for doc in norm_bible[:1000]]\n",
    "model = Word2Vec(sentences, min_count = 1, size = 150, window = 10, sg = 1, workers = 8)\n",
    "model.train(sentences, total_examples = model.corpus_count, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "GiWCf1_sM_Fm"
   },
   "source": [
    "Trong đó có một số tham số quan trọng trong Word2Vec như sau:\n",
    "\n",
    "* size: Kích thước của ma trận nhúng.\n",
    "* window: Kích thước cửa sổ được sử dụng để khởi tạo các n-gram.\n",
    "* sg: Nhận 2 giá trị {0, 1}. Nếu là 0: phương pháp CBOW, nếu là 1: skip-grams.\n",
    "* wokers: Số core CPU được huy động để huấn luyện. Càng nhiều core tốc độ huấn luyện càng nhanh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "VIxe8ttyJwbB",
    "outputId": "2f16d0ce-e89f-47b8-f13c-514087a82004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding vector shape:  (150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00468112,  0.16854957,  0.01438654, -0.05265754,  0.14835362,\n",
       "        0.16904514,  0.13904604, -0.389859  , -0.27150822, -0.20627081,\n",
       "        0.14461713,  0.14430152, -0.6332871 ,  0.26111943, -0.62677157,\n",
       "        0.31035894, -0.06819729, -0.09760765,  0.03894788,  0.08955805,\n",
       "        0.37997362, -0.11426175, -0.24091758,  0.21360792,  0.21109544,\n",
       "       -0.35530874, -0.11317078,  0.32211563, -0.20230685,  0.13549906,\n",
       "        0.35079992,  0.12786317,  0.37597153,  0.23084798, -0.26415083,\n",
       "        0.26244414,  0.07653711, -0.50538695,  0.2834227 ,  0.20041615,\n",
       "        0.0674964 ,  0.01574622,  0.42599007, -0.16902669,  0.4619288 ,\n",
       "       -0.30663815, -0.27341986, -0.02219926,  0.63796794, -0.05939501,\n",
       "       -0.2685611 ,  0.05930207,  0.14947902,  0.12269587, -0.13594696,\n",
       "        0.07239573,  0.43372607,  0.05574725,  0.47558722,  0.01881623,\n",
       "       -0.67344916,  0.02950857,  0.25267097,  0.34665427, -0.2924466 ,\n",
       "       -0.3019795 , -0.40723747,  0.22149928,  0.09181835, -0.2102407 ,\n",
       "        0.3960522 ,  0.33556274, -0.35339063, -0.06665646,  0.03615884,\n",
       "       -0.04388156,  0.78695637,  0.07246866, -0.10199204,  0.0916383 ,\n",
       "        0.21444249, -0.12521476,  0.21644261,  0.313953  ,  0.09498119,\n",
       "        0.09211312, -0.32217   ,  0.00767796,  0.10209975,  0.42178214,\n",
       "        0.2544956 ,  0.22292465,  0.40680042,  0.33036977,  0.01546835,\n",
       "        0.58035815,  0.02209221,  0.13864015, -0.29937524, -0.14904518,\n",
       "       -0.23794968,  0.42327195, -0.18905397,  0.27455658,  0.02095251,\n",
       "        0.17467256, -0.10094242,  0.12557817, -0.07476169, -0.12560274,\n",
       "       -0.23021477,  0.20215885,  0.03653349, -0.14345853, -0.09200411,\n",
       "        0.23576148,  0.4421827 ,  0.32885996,  0.01603066,  0.20421034,\n",
       "       -0.17228857,  0.08368498,  0.22233133, -0.03762142, -0.30013585,\n",
       "        0.2022897 , -0.26879194,  0.20945235,  0.3739482 , -0.41301957,\n",
       "       -0.17121448, -0.49887335,  0.15468772, -0.42403707, -0.40717396,\n",
       "       -0.2646839 ,  0.30112094,  0.16615865, -0.44990897,  0.17940831,\n",
       "       -0.06671996,  0.1638959 ,  0.4423822 ,  0.24692418, -0.09863947,\n",
       "       -0.06495735, -0.5664116 ,  0.52329963,  0.01605448,  0.33879682],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lấy véc tơ biểu diễn của từ king\n",
    "print('embedding vector shape: ', model.wv['king'].shape)\n",
    "model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "jSPotCY9OXfC",
    "outputId": "29f683b4-5b64-4d4d-bb36-36f8c7b67516"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('admah', 0.8957317471504211),\n",
       " ('tidal', 0.872719407081604),\n",
       " ('zeboiim', 0.8709798455238342),\n",
       " ('shinar', 0.870228111743927),\n",
       " ('elam', 0.8701319098472595),\n",
       " ('ellasar', 0.8675274848937988),\n",
       " ('arioch', 0.8656346201896667),\n",
       " ('chedorlaomer', 0.8627975583076477),\n",
       " ('amraphel', 0.861689031124115),\n",
       " ('bela', 0.8449435830116272)]"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lấy các từ có mối liên hệ gần nhất với 1 từ dựa trên khoảng cách\n",
    "model.most_similar('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tài liệu tham khảo\n",
    "\n",
    "1. [SVD - phamdinhkhanh](https://www.kaggle.com/phamdinhkhanh/singular-value-decomposition)\n",
    "2. [Auto Encoder - standford university](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)\n",
    "3. [word2vec gensim package](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "4. [Efficient Estimation of Word Representations in Vector Space - Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean](https://arxiv.org/abs/1301.3781)\n",
    "5. [Vector Representations of Words - tensorflow](https://www.tensorflow.org/tutorials/representation/word2vec)\n",
    "6. [The Skip-gram Model - kdnuggets.com](https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html)\n",
    "7. [The Continuous Bag of Words (CBOW) - kdnuggets.com](https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2019-04-29-ModelWord2Vec.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
